    "#!/usr/bin/env python3\n",
 
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, matthews_corrcoef, \n",
    "                             confusion_matrix, classification_report, roc_curve, auc)\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    
    "os.chdir(\"/Users/medhajha/Downloads/paper/hormonesbrpr/hormonesbp\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    
    "print(\"Working Directory:\", os.getcwd())\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS 1: TUMOR VS NORMAL CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    print(\"\\n>>> Loading Tumor vs Normal data...\")\n",
    "    dat1 = pd.read_csv(\"results/data/expression_tumor_vs_normal.csv\")\n",
    "    \n",
    "    metadata_cols = ['label', 'cancerType', 'sampleID', 'sampleType']\n",
    "    gene_cols = [col for col in dat1.columns if col not in metadata_cols]\n",
    "    \n",
    "    X1 = dat1[gene_cols]\n",
    "    y1 = dat1['label'].values\n",
    "    \n",
    "    print(f\"✓ Data loaded: {X1.shape}\")\n",
    "    print(f\"  Tumor: {sum(y1 == 1)}, Normal: {sum(y1 == 0)}\")\n",
    "    \n",
    "    # Split\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "        X1, y1, test_size=0.2, random_state=42, stratify=y1\n",
    "    )\n",
    "    print(f\"✓ Train: {X1_train.shape[0]}, Test: {X1_test.shape[0]}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    print(\"\\n>>> Training XGBoost...\")\n",
    "    xgb1 = XGBClassifier(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, use_label_encoder=False,\n",
    "        eval_metric=\"logloss\", verbose=0\n",
    "    )\n",
    "    \n",
    "    # CV\n",
    "    print(\">>> 5-fold cross-validation...\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_acc = cross_val_score(xgb1, X1_train, y1_train, cv=cv, scoring=\"accuracy\")\n",
    "    cv_auc = cross_val_score(xgb1, X1_train, y1_train, cv=cv, scoring=\"roc_auc\")\n",
    "    cv_mcc = cross_val_score(xgb1, X1_train, y1_train, cv=cv, scoring=\"matthews_corrcoef\")\n",
    "    \n",
    "    print(f\"\\n✓ 5-Fold CV Results (Tumor vs Normal):\")\n",
    "    print(f\"  Accuracy: {cv_acc.mean():.4f} ± {cv_acc.std():.4f}\")\n",
    "    print(f\"  AUC-ROC:  {cv_auc.mean():.4f} ± {cv_auc.std():.4f}\")\n",
    "    print(f\"  MCC:      {cv_mcc.mean():.4f} ± {cv_mcc.std():.4f}\")\n",
    "    \n",
    "    # Fit\n",
    "    xgb1.fit(X1_train, y1_train)\n",
    "    \n",
    "    # Test\n",
    "    print(\"\\n>>> Test Set Results:\")\n",
    "    y1_pred = xgb1.predict(X1_test)\n",
    "    y1_prob = xgb1.predict_proba(X1_test)[:, 1]\n",
    "    \n",
    "    test_acc = accuracy_score(y1_test, y1_pred)\n",
    "    test_auc = roc_auc_score(y1_test, y1_prob)\n",
    "    test_mcc = matthews_corrcoef(y1_test, y1_pred)\n",
    "    \n",
    "    print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  AUC-ROC:  {test_auc:.4f}\")\n",
    "    print(f\"  MCC:      {test_mcc:.4f}\")\n",
    "    \n",
    "    cm1 = confusion_matrix(y1_test, y1_pred)\n",
    "    sensitivity1 = cm1[1,1] / (cm1[1,1] + cm1[1,0])\n",
    "    specificity1 = cm1[0,0] / (cm1[0,0] + cm1[0,1])\n",
    "    \n",
    "    print(f\"\\n  Confusion Matrix:\")\n",
    "    print(f\"    TN: {cm1[0,0]}, FP: {cm1[0,1]}\")\n",
    "    print(f\"    FN: {cm1[1,0]}, TP: {cm1[1,1]}\")\n",
    "    print(f\"  Sensitivity (TPR): {sensitivity1:.4f}\")\n",
    "    print(f\"  Specificity (TNR): {specificity1:.4f}\")\n",
    "    \n",
    "    
    "    print(\"\\n>>> Creating Confusion Matrix heatmap...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Normal', 'Tumor'],\n",
    "                yticklabels=['Normal', 'Tumor'],\n",
    "                ax=ax, annot_kws={'size': 14})\n",
    "    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Confusion Matrix: Tumor vs Normal\\nAccuracy={:.4f}, AUC-ROC={:.4f}'.format(test_acc, test_auc),\n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure7A_confusion_matrix_tumor_vs_normal.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    
    "    print(\">>> Creating ROC curve...\")\n",
    "    fpr1, tpr1, _ = roc_curve(y1_test, y1_prob)\n",
    "    roc_auc1 = auc(fpr1, tpr1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.plot(fpr1, tpr1, color='darkorange', lw=3, label=f'ROC Curve (AUC = {roc_auc1:.4f})')\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    ax.fill_between(fpr1, tpr1, alpha=0.2, color='darkorange')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('ROC Curve: Tumor vs Normal Classification', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc=\"lower right\", fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure7B_roc_curve_tumor_vs_normal.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure7B_roc_curve_tumor_vs_normal.png\")\n",
    "    \n",
    "    
    "    print(\"\\n>>> SHAP Analysis...\")\n",
    "    explainer1 = shap.TreeExplainer(xgb1)\n",
    "    shap_values1 = explainer1.shap_values(X1_test)\n",
    "    \n",
    "    
    "    print(\"  Creating SHAP summary plot (violin)...\")\n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    shap.summary_plot(shap_values1, X1_test, show=False, plot_type=\"violin\", max_display=20)\n",
    "    plt.title(\"SHAP Summary Plot: Tumor vs Normal\\n(Violin plot showing feature distributions)\", \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"SHAP Value (Model Output Impact)\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure7C_SHAP_summary_violin_tumor_vs_normal.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    
    "    \n",
    "    # SHAP Bar Plot (Feature Importance)\n",
    "    print(\"  Creating SHAP bar plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values1, X1_test, show=False, plot_type=\"bar\", max_display=15)\n",
    "    plt.title(\"SHAP Feature Importance: Tumor vs Normal\\n(Mean |SHAP| values)\", \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Mean |SHAP Value|\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure7D_SHAP_bar_tumor_vs_normal.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure7D_SHAP_bar_tumor_vs_normal.png\")\n",
    "    \n",
    "    
    "    print(\"  Creating SHAP decision plot...\")\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        shap.decision_plot(explainer1.expected_value, shap_values1[:50], X1_test.iloc[:50], \n",
    "                          highlight=y1_test[:50], color_bar=False, show=False)\n",
    "        plt.title(\"SHAP Decision Plot: Tumor vs Normal\\n(First 50 test samples)\", \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"results/figures/Figure7E_SHAP_decision_tumor_vs_normal.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ✓ Figure7E_SHAP_decision_tumor_vs_normal.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Decision plot skipped: {str(e)}\")\n",
    "    \n",
    "    # Top genes\n",
    "    mean_shap1 = np.abs(shap_values1).mean(axis=0)\n",
    "    top_genes1 = pd.DataFrame({\n",
    "        \"gene\": X1.columns,\n",
    "        \"mean_abs_shap\": mean_shap1\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "    \n",
    "    top_genes1.to_csv(\"results/tables/Table5_top_genes_SHAP_tumor_vs_normal.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Top 10 genes (Tumor vs Normal):\")\n",
    "    print(top_genes1.head(10).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR in Analysis 1: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 2: BRCA VS PRAD CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    print(\"\\n>>> Loading BRCA vs PRAD data...\")\n",
    "    dat2 = pd.read_csv(\"results/data/expression_brca_vs_prad.csv\")\n",
    "    \n",
    "    metadata_cols2 = ['label', 'tumorStatus', 'sampleID']\n",
    "    gene_cols2 = [col for col in dat2.columns if col not in metadata_cols2]\n",
    "    \n",
    "    X2 = dat2[gene_cols2]\n",
    "    y2 = dat2['label'].values\n",
    "    \n",
    "    print(f\"✓ Data loaded: {X2.shape}\")\n",
    "    print(f\"  BRCA: {sum(y2 == 1)}, PRAD: {sum(y2 == 0)}\")\n",
    "    \n",
    "    # Split\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "        X2, y2, test_size=0.2, random_state=42, stratify=y2\n",
    "    )\n",
    "    print(f\"✓ Train: {X2_train.shape[0]}, Test: {X2_test.shape[0]}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    print(\"\\n>>> Training XGBoost...\")\n",
    "    xgb2 = XGBClassifier(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, use_label_encoder=False,\n",
    "        eval_metric=\"logloss\", verbose=0\n",
    "    )\n",
    "    \n",
    "    # CV\n",
    "    print(\">>> 5-fold cross-validation...\")\n",
    "    cv_acc2 = cross_val_score(xgb2, X2_train, y2_train, cv=cv, scoring=\"accuracy\")\n",
    "    cv_auc2 = cross_val_score(xgb2, X2_train, y2_train, cv=cv, scoring=\"roc_auc\")\n",
    "    cv_mcc2 = cross_val_score(xgb2, X2_train, y2_train, cv=cv, scoring=\"matthews_corrcoef\")\n",
    "    \n",
    "    print(f\"\\n✓ 5-Fold CV Results (BRCA vs PRAD):\")\n",
    "    print(f\"  Accuracy: {cv_acc2.mean():.4f} ± {cv_acc2.std():.4f}\")\n",
    "    print(f\"  AUC-ROC:  {cv_auc2.mean():.4f} ± {cv_auc2.std():.4f}\")\n",
    "    print(f\"  MCC:      {cv_mcc2.mean():.4f} ± {cv_mcc2.std():.4f}\")\n",
    "    \n",
    "    # Fit\n",
    "    xgb2.fit(X2_train, y2_train)\n",
    "    \n",
    "    # Test\n",
    "    print(\"\\n>>> Test Set Results:\")\n",
    "    y2_pred = xgb2.predict(X2_test)\n",
    "    y2_prob = xgb2.predict_proba(X2_test)[:, 1]\n",
    "    \n",
    "    test_acc2 = accuracy_score(y2_test, y2_pred)\n",
    "    test_auc2 = roc_auc_score(y2_test, y2_prob)\n",
    "    test_mcc2 = matthews_corrcoef(y2_test, y2_pred)\n",
    "    \n",
    "    print(f\"  Accuracy: {test_acc2:.4f}\")\n",
    "    print(f\"  AUC-ROC:  {test_auc2:.4f}\")\n",
    "    print(f\"  MCC:      {test_mcc2:.4f}\")\n",
    "    \n",
    "    cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "    sensitivity2 = cm2[1,1] / (cm2[1,1] + cm2[1,0])\n",
    "    specificity2 = cm2[0,0] / (cm2[0,0] + cm2[0,1])\n",
    "    \n",
    "    print(f\"\\n  Confusion Matrix:\")\n",
    "    print(f\"    PRAD: {cm2[0,0]}, Misclassified as BRCA: {cm2[0,1]}\")\n",
    "    print(f\"    Misclassified as PRAD: {cm2[1,0]}, BRCA: {cm2[1,1]}\")\n",
    "    print(f\"  Sensitivity (BRCA): {sensitivity2:.4f}\")\n",
    "    print(f\"  Specificity (PRAD): {specificity2:.4f}\")\n",
    "    \n",
    "   
    "    print(\"\\n>>> Creating Confusion Matrix heatmap...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm2, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "                xticklabels=['PRAD', 'BRCA'],\n",
    "                yticklabels=['PRAD', 'BRCA'],\n",
    "                ax=ax, annot_kws={'size': 14})\n",
    "    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Confusion Matrix: BRCA vs PRAD\\nAccuracy={:.4f}, AUC-ROC={:.4f}'.format(test_acc2, test_auc2),\n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure8A_confusion_matrix_brca_vs_prad.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure8A_confusion_matrix_brca_vs_prad.png\")\n",
    "    \n",
    "    
    "    print(\">>> Creating ROC curve...\")\n",
    "    fpr2, tpr2, _ = roc_curve(y2_test, y2_prob)\n",
    "    roc_auc2 = auc(fpr2, tpr2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.plot(fpr2, tpr2, color='darkgreen', lw=3, label=f'ROC Curve (AUC = {roc_auc2:.4f})')\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    ax.fill_between(fpr2, tpr2, alpha=0.2, color='darkgreen')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('ROC Curve: BRCA vs PRAD Classification', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc=\"lower right\", fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure8B_roc_curve_brca_vs_prad.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure8B_roc_curve_brca_vs_prad.png\")\n",
    "    \n",
    "    
    "    print(\"\\n>>> SHAP Analysis...\")\n",
    "    explainer2 = shap.TreeExplainer(xgb2)\n",
    "    shap_values2 = explainer2.shap_values(X2_test)\n",
    "    \n",
    "    
    "    print(\"  Creating SHAP summary plot (violin)...\")\n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    shap.summary_plot(shap_values2, X2_test, show=False, plot_type=\"violin\", max_display=15)\n",
    "    plt.title(\"SHAP Summary Plot: BRCA vs PRAD\\n(Violin plot showing feature distributions)\", \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"SHAP Value (Model Output Impact)\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure8C_SHAP_summary_violin_brca_vs_prad.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure8C_SHAP_summary_violin_brca_vs_prad.png\")\n",
    "    \n",
    "    
    "    print(\"  Creating SHAP bar plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values2, X2_test, show=False, plot_type=\"bar\", max_display=15)\n",
    "    plt.title(\"SHAP Feature Importance: BRCA vs PRAD\\n(Mean |SHAP| values)\", \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Mean |SHAP Value|\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/Figure8D_SHAP_bar_brca_vs_prad.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ✓ Figure8D_SHAP_bar_brca_vs_prad.png\")\n",
    "    \n",
    "    
    "    print(\"  Creating SHAP decision plot...\")\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        shap.decision_plot(explainer2.expected_value, shap_values2[:50], X2_test.iloc[:50], \n",
    "                          highlight=y2_test[:50], color_bar=False, show=False)\n",
    "        plt.title(\"SHAP Decision Plot: BRCA vs PRAD\\n(First 50 test samples)\", \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"results/figures/Figure8E_SHAP_decision_brca_vs_prad.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ✓ Figure8E_SHAP_decision_brca_vs_prad.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Decision plot skipped: {str(e)}\")\n",
    "    \n",
    "   
    "    mean_shap2 = np.abs(shap_values2).mean(axis=0)\n",
    "    top_genes2 = pd.DataFrame({\n",
    "        \"gene\": X2.columns,\n",
    "        \"mean_abs_shap\": mean_shap2\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "    \n",
    "    top_genes2.to_csv(\"results/tables/Table6_top_genes_SHAP_brca_vs_prad.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Top 10 genes (BRCA vs PRAD):\")\n",
    "    print(top_genes2.head(10).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR in Analysis 2: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    
    "try:\n",
    "    print(\"\\n>>> Creating summary table...\")\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Analysis': ['Tumor vs Normal', 'BRCA vs PRAD'],\n",
    "        'CV_Accuracy': [f\"{cv_acc.mean():.4f} ± {cv_acc.std():.4f}\", \n",
    "                       f\"{cv_acc2.mean():.4f} ± {cv_acc2.std():.4f}\"],\n",
    "        'CV_AUC': [f\"{cv_auc.mean():.4f} ± {cv_auc.std():.4f}\",\n",
    "                  f\"{cv_auc2.mean():.4f} ± {cv_auc2.std():.4f}\"],\n",
    "        'Test_Accuracy': [f\"{test_acc:.4f}\", f\"{test_acc2:.4f}\"],\n",
    "        'Test_AUC': [f\"{test_auc:.4f}\", f\"{test_auc2:.4f}\"],\n",
    "        'Test_MCC': [f\"{test_mcc:.4f}\", f\"{test_mcc2:.4f}\"]\n",
    "    })\n",
    "    \n",
    "    summary_df.to_csv(\"results/tables/Table7_model_performance_summary.csv\", index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHASE 5 COMPLETE: XGBOOST + SHAP ANALYSIS ✓\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n✓ PERFORMANCE SUMMARY:\\n\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(\"  Analysis 1 - Tumor vs Normal:\")\n",
    "    print(\"    ✓ Figure7A: Confusion Matrix\")\n",
    "    print(\"    ✓ Figure7B: ROC Curve\")\n",
    "    print(\"    ✓ Figure7C: SHAP Violin Plot\")\n",
    "    print(\"    ✓ Figure7D: SHAP Bar Plot\")\n",
    "    print(\"    ✓ Figure7E: SHAP Decision Plot\")\n",
    "    print(\"    ✓ Table5: Top genes by SHAP\")\n",
    "    print(\"\\n  Analysis 2 - BRCA vs PRAD:\")\n",
    "    print(\"    ✓ Figure8A: Confusion Matrix\")\n",
    "    print(\"    ✓ Figure8B: ROC Curve\")\n",
    "    print(\"    ✓ Figure8C: SHAP Violin Plot\")\n",
    "    print(\"    ✓ Figure8D: SHAP Bar Plot\")\n",
    "    print(\"    ✓ Figure8E: SHAP Decision Plot\")\n",
    "    print(\"    ✓ Table6: Top genes by SHAP\")\n",
    "    print(\"\\n  Summary:\")\n",
    "    print(\"    ✓ Table7: Model Performance Summary\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"READY FOR PHASE 6: SURVIVAL ANALYSIS & PATHWAY ENRICHMENT\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR in summary: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11dede7-9da5-4959-b54a-fe5ec2703232",
   "metadata": {},
   "outputs": [],
   "source": [
    
